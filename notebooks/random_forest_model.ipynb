{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Corrected Random Forest Model with Proper SMOTE Implementation\n",
    "\n",
    "This notebook implements a corrected Random Forest model for stroke prediction with proper SMOTE usage to handle class imbalance.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-03T05:58:08.201990Z",
     "start_time": "2025-10-03T05:58:08.192034Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (classification_report, confusion_matrix, \n",
    "                           roc_curve, auc, precision_recall_curve, \n",
    "                           f1_score, precision_score, recall_score)\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ],
   "outputs": [],
   "execution_count": 233
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Preprocessed Data\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-03T05:58:08.402207Z",
     "start_time": "2025-10-03T05:58:08.245266Z"
    }
   },
   "source": [
    "# Load the corrected preprocessed dataset\n",
    "df = pd.read_csv(\"../preprocessed_stroke_data.csv\")\n",
    "\n",
    "print(\"Dataset Information:\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"Columns: {df.columns.tolist()}\")\n",
    "print(f\"\\nData types:\")\n",
    "print(df.dtypes)\n",
    "print(f\"\\nMissing values:\")\n",
    "print(df.isnull().sum())\n",
    "print(f\"\\nTarget distribution:\")\n",
    "print(df['Stroke'].value_counts())\n",
    "print(f\"\\nTarget distribution (%):\")\n",
    "print(df['Stroke'].value_counts(normalize=True) * 100)\n",
    "\n",
    "# Check class imbalance\n",
    "stroke_count = df['Stroke'].sum()\n",
    "total_count = len(df)\n",
    "imbalance_ratio = (total_count - stroke_count) / stroke_count\n",
    "print(f\"\\nClass imbalance ratio: {imbalance_ratio:.2f}:1 (No Stroke:Stroke)\")\n",
    "print(\"This severe imbalance requires SMOTE for proper model training.\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Information:\n",
      "Shape: (41000, 17)\n",
      "Columns: ['Age', 'Sex', 'Hypertension', 'Heart_Disease', 'Work_Type', 'Residence_Type', 'Average_Glucose_Level', 'BMI', 'Smoking_Status', 'Physical_Activity', 'Alcohol_Intake', 'Stress_Level', 'Blood_Pressure', 'Cholesterol', 'Family_History', 'MRI_Result', 'Stroke']\n",
      "\n",
      "Data types:\n",
      "Age                        int64\n",
      "Sex                        int64\n",
      "Hypertension               int64\n",
      "Heart_Disease              int64\n",
      "Work_Type                  int64\n",
      "Residence_Type             int64\n",
      "Average_Glucose_Level    float64\n",
      "BMI                      float64\n",
      "Smoking_Status             int64\n",
      "Physical_Activity          int64\n",
      "Alcohol_Intake             int64\n",
      "Stress_Level             float64\n",
      "Blood_Pressure             int64\n",
      "Cholesterol                int64\n",
      "Family_History             int64\n",
      "MRI_Result               float64\n",
      "Stroke                     int64\n",
      "dtype: object\n",
      "\n",
      "Missing values:\n",
      "Age                      0\n",
      "Sex                      0\n",
      "Hypertension             0\n",
      "Heart_Disease            0\n",
      "Work_Type                0\n",
      "Residence_Type           0\n",
      "Average_Glucose_Level    0\n",
      "BMI                      0\n",
      "Smoking_Status           0\n",
      "Physical_Activity        0\n",
      "Alcohol_Intake           0\n",
      "Stress_Level             0\n",
      "Blood_Pressure           0\n",
      "Cholesterol              0\n",
      "Family_History           0\n",
      "MRI_Result               0\n",
      "Stroke                   0\n",
      "dtype: int64\n",
      "\n",
      "Target distribution:\n",
      "Stroke\n",
      "0    36849\n",
      "1     4151\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Target distribution (%):\n",
      "Stroke\n",
      "0    89.87561\n",
      "1    10.12439\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Class imbalance ratio: 8.88:1 (No Stroke:Stroke)\n",
      "This severe imbalance requires SMOTE for proper model training.\n"
     ]
    }
   ],
   "execution_count": 234
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data for Training\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-03T05:58:08.501486Z",
     "start_time": "2025-10-03T05:58:08.423647Z"
    }
   },
   "source": [
    "# Separate features and target\n",
    "X = df.drop('Stroke', axis=1)\n",
    "y = df['Stroke']\n",
    "\n",
    "# Get feature names\n",
    "feature_names = X.columns.tolist()\n",
    "print(f\"Features ({len(feature_names)}): {feature_names}\")\n",
    "\n",
    "# Initial train-test split (before SMOTE to avoid data leakage)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(f\"\\nTrain set shape: {X_train.shape}\")\n",
    "print(f\"Test set shape: {X_test.shape}\")\n",
    "print(f\"\\nTrain set target distribution:\")\n",
    "print(y_train.value_counts())\n",
    "print(f\"\\nTest set target distribution:\")\n",
    "print(y_test.value_counts())\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features (16): ['Age', 'Sex', 'Hypertension', 'Heart_Disease', 'Work_Type', 'Residence_Type', 'Average_Glucose_Level', 'BMI', 'Smoking_Status', 'Physical_Activity', 'Alcohol_Intake', 'Stress_Level', 'Blood_Pressure', 'Cholesterol', 'Family_History', 'MRI_Result']\n",
      "\n",
      "Train set shape: (32800, 16)\n",
      "Test set shape: (8200, 16)\n",
      "\n",
      "Train set target distribution:\n",
      "Stroke\n",
      "0    29479\n",
      "1     3321\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test set target distribution:\n",
      "Stroke\n",
      "0    7370\n",
      "1     830\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 235
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply SMOTE to Training Data Only\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-03T05:58:08.709817Z",
     "start_time": "2025-10-03T05:58:08.541732Z"
    }
   },
   "source": [
    "# Apply SMOTE only to training data to avoid data leakage\n",
    "print(\"Applying SMOTE to training data only...\")\n",
    "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "print(f\"Before SMOTE - Train set shape: {X_train.shape}\")\n",
    "print(f\"After SMOTE - Train set shape: {X_train_resampled.shape}\")\n",
    "print(f\"\\nBefore SMOTE - Train target distribution:\")\n",
    "print(y_train.value_counts())\n",
    "print(f\"\\nAfter SMOTE - Train target distribution:\")\n",
    "print(pd.Series(y_train_resampled).value_counts())\n",
    "\n",
    "# Note: Test set remains unchanged (no SMOTE applied)\n",
    "print(f\"\\nTest set remains unchanged: {X_test.shape}\")\n",
    "print(\"Test set target distribution:\")\n",
    "print(y_test.value_counts())\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying SMOTE to training data only...\n",
      "Before SMOTE - Train set shape: (32800, 16)\n",
      "After SMOTE - Train set shape: (58958, 16)\n",
      "\n",
      "Before SMOTE - Train target distribution:\n",
      "Stroke\n",
      "0    29479\n",
      "1     3321\n",
      "Name: count, dtype: int64\n",
      "\n",
      "After SMOTE - Train target distribution:\n",
      "Stroke\n",
      "0    29479\n",
      "1    29479\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test set remains unchanged: (8200, 16)\n",
      "Test set target distribution:\n",
      "Stroke\n",
      "0    7370\n",
      "1     830\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 236
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Scaling\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-03T05:58:08.788944Z",
     "start_time": "2025-10-03T05:58:08.730770Z"
    }
   },
   "source": [
    "# Scale features (fit on training data, transform both train and test)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_resampled)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"Feature scaling completed:\")\n",
    "print(f\"Train set scaled shape: {X_train_scaled.shape}\")\n",
    "print(f\"Test set scaled shape: {X_test_scaled.shape}\")\n",
    "print(f\"Scaler fitted on training data only to prevent data leakage\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature scaling completed:\n",
      "Train set scaled shape: (58958, 16)\n",
      "Test set scaled shape: (8200, 16)\n",
      "Scaler fitted on training data only to prevent data leakage\n"
     ]
    }
   ],
   "execution_count": 237
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Random Forest Model\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-03T05:58:12.291851Z",
     "start_time": "2025-10-03T05:58:08.834799Z"
    }
   },
   "source": [
    "# Train Random Forest with optimized parameters\n",
    "print(\"Training Random Forest model...\")\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=15,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=2,\n",
    "    max_features='sqrt',\n",
    "    random_state=42,\n",
    "    class_weight='balanced',  # Additional balancing\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "rf_model.fit(X_train_scaled, y_train_resampled)\n",
    "\n",
    "print(\"Model training completed!\")\n",
    "print(f\"Number of trees: {rf_model.n_estimators}\")\n",
    "print(f\"Max depth: {rf_model.max_depth}\")\n",
    "print(f\"Feature importance shape: {rf_model.feature_importances_.shape}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Random Forest model...\n",
      "Model training completed!\n",
      "Number of trees: 100\n",
      "Max depth: 15\n",
      "Feature importance shape: (16,)\n"
     ]
    }
   ],
   "execution_count": 238
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-03T05:58:15.648953Z",
     "start_time": "2025-10-03T05:58:14.645436Z"
    }
   },
   "source": [
    "# Make predictions\n",
    "y_pred_train = rf_model.predict(X_train_scaled)\n",
    "y_pred_test = rf_model.predict(X_test_scaled)\n",
    "y_pred_proba_test = rf_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Calculate metrics\n",
    "train_accuracy = rf_model.score(X_train_scaled, y_train_resampled)\n",
    "test_accuracy = rf_model.score(X_test_scaled, y_test)\n",
    "\n",
    "print(\"=== MODEL PERFORMANCE ===\")\n",
    "print(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "# Classification report\n",
    "print(\"\\n=== CLASSIFICATION REPORT (Test Set) ===\")\n",
    "print(classification_report(y_test, y_pred_test, target_names=['No Stroke', 'Stroke']))\n",
    "\n",
    "# Confusion Matrix\n",
    "print(\"\\n=== CONFUSION MATRIX (Test Set) ===\")\n",
    "cm = confusion_matrix(y_test, y_pred_test)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "print(f\"True Negatives: {cm[0,0]}\")\n",
    "print(f\"False Positives: {cm[0,1]}\")\n",
    "print(f\"False Negatives: {cm[1,0]}\")\n",
    "print(f\"True Positives: {cm[1,1]}\")\n",
    "\n",
    "# Additional metrics\n",
    "precision = precision_score(y_test, y_pred_test)\n",
    "recall = recall_score(y_test, y_pred_test)\n",
    "f1 = f1_score(y_test, y_pred_test)\n",
    "\n",
    "print(f\"\\n=== ADDITIONAL METRICS ===\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== MODEL PERFORMANCE ===\n",
      "Training Accuracy: 0.8657\n",
      "Test Accuracy: 0.7193\n",
      "\n",
      "=== CLASSIFICATION REPORT (Test Set) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   No Stroke       0.90      0.77      0.83      7370\n",
      "      Stroke       0.10      0.23      0.14       830\n",
      "\n",
      "    accuracy                           0.72      8200\n",
      "   macro avg       0.50      0.50      0.49      8200\n",
      "weighted avg       0.82      0.72      0.76      8200\n",
      "\n",
      "\n",
      "=== CONFUSION MATRIX (Test Set) ===\n",
      "Confusion Matrix:\n",
      "[[5704 1666]\n",
      " [ 636  194]]\n",
      "True Negatives: 5704\n",
      "False Positives: 1666\n",
      "False Negatives: 636\n",
      "True Positives: 194\n",
      "\n",
      "=== ADDITIONAL METRICS ===\n",
      "Precision: 0.1043\n",
      "Recall: 0.2337\n",
      "F1-Score: 0.1442\n"
     ]
    }
   ],
   "execution_count": 239
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the Corrected Model\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-03T05:58:15.832063Z",
     "start_time": "2025-10-03T05:58:15.684899Z"
    }
   },
   "source": [
    "# Save the corrected model with all necessary components\n",
    "model_package = {\n",
    "    'model': rf_model,\n",
    "    'scaler': scaler,\n",
    "    'feature_names': feature_names,\n",
    "    'version': '3.0_corrected',\n",
    "    'training_accuracy': train_accuracy,\n",
    "    'test_accuracy': test_accuracy,\n",
    "    'precision': precision,\n",
    "    'recall': recall,\n",
    "    'f1_score': f1,\n",
    "    'smote_applied': True,\n",
    "    'preprocessing_notes': 'SMOTE applied only to training data to prevent data leakage'\n",
    "}\n",
    "\n",
    "# Save the model\n",
    "with open(\"../models/random_forest.pkl\", \"wb\") as f:\n",
    "    pickle.dump(model_package, f)\n",
    "\n",
    "print(\"=== MODEL SAVED SUCCESSFULLY ===\")\n",
    "print(f\"Model saved to: models/random_forest.pkl\")\n",
    "print(f\"Model version: {model_package['version']}\")\n",
    "print(f\"Test accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"Expected {len(feature_names)} features in order: {feature_names}\")\n",
    "\n",
    "print(\"\\n=== KEY IMPROVEMENTS IN THIS CORRECTED VERSION ===\")\n",
    "print(\"1. ✓ SMOTE applied only to training data (no data leakage)\")\n",
    "print(\"2. ✓ Proper train-test split before SMOTE\")\n",
    "print(\"3. ✓ Feature scaling fitted only on training data\")\n",
    "print(\"4. ✓ Comprehensive evaluation metrics\")\n",
    "print(\"5. ✓ Balanced class handling with both SMOTE and class_weight\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== MODEL SAVED SUCCESSFULLY ===\n",
      "Model saved to: models/random_forest.pkl\n",
      "Model version: 3.0_corrected\n",
      "Test accuracy: 0.7193\n",
      "F1 Score: 0.1442\n",
      "Expected 16 features in order: ['Age', 'Sex', 'Hypertension', 'Heart_Disease', 'Work_Type', 'Residence_Type', 'Average_Glucose_Level', 'BMI', 'Smoking_Status', 'Physical_Activity', 'Alcohol_Intake', 'Stress_Level', 'Blood_Pressure', 'Cholesterol', 'Family_History', 'MRI_Result']\n",
      "\n",
      "=== KEY IMPROVEMENTS IN THIS CORRECTED VERSION ===\n",
      "1. ✓ SMOTE applied only to training data (no data leakage)\n",
      "2. ✓ Proper train-test split before SMOTE\n",
      "3. ✓ Feature scaling fitted only on training data\n",
      "4. ✓ Comprehensive evaluation metrics\n",
      "5. ✓ Balanced class handling with both SMOTE and class_weight\n"
     ]
    }
   ],
   "execution_count": 240
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
